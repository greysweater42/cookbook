\documentclass[12pt, a4paper]{article}

%%% polskie znaki
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[MeX]{polski}

%% czcionka
\usepackage{lmodern}

%%% rozmiar papieru, marginesy
\usepackage[a4paper, margin=2cm]{geometry}

%%% obrazki na poziomie
\usepackage{float}

%%% wcięcia w~pierwszym akapicie
\usepackage{indentfirst}

%%% wykresy obok siebie
\usepackage{subcaption}

%%% pogrubiona czcionka w~symbolach matematycznych
\usepackage{bm}

%%% obracanie nagłówków tabel
\usepackage{rotating}

%%% podpisy pod wykresami
\usepackage{caption}

%%% obrazek obok tekstu
\usepackage{wrapfig}


\begin{document}
\SweaveOpts{concordance=TRUE}

imię i nazwisko

nr indeksu: 

studia stacjonarne magisterskie w~SGH

\vspace{5mm} 

przedmiot: Ekonometeria bayesowska

prowadzący:

data: 28 stycznia 2017r.

\vspace{10mm} 

\begin{center}

    {\large Praca zaliczeniowa z~przedmiotu}

    \vspace{3mm} 

    {\large Ekonometria bayesowska}

    \vspace{15mm} 

    {\Huge Determinanty stopy bezrobocia}
    \\~\\
    {\Huge w krajach Unii Europejskiej}

\end{center}

\newpage

\section{Wstęp}

Stopa bezrobocia jest jednym z~podstawowym wskaźników ekonomicznych obrazujących ogólnie rozumiany poziom \textit{jakości życia} w~danym regionie. W~związku z~tym może być ona obiektem zainteresowania chociażby rządu, mającego na celu poprawę jakości życia społeczeństwa poprzez zmniejszenie jej wielkości. W~takim przedsięwzięciu kluczowe jest zrozumienie natury i~przyczyn zjawiska, jakim jest bezrobocie. Możliwe jest zbadanie relacji pomiędzy stopą bezrobocia a~innymi wskaźnikami ekonomicznymi, na które rząd ma wpływ w~sposób bezpośredni (liczba tworzonych miejsc pracy w~firmach państwowych) lub pośredni (dostosowanie przepisów w~taki sposób, aby zwiększyć popyt na nowych pracowników na rynku). Takimi wskaźnikami może być na przykład siła związków zawodowych, stopa inflacji, charakter zatrudniania pracowników (umowa o~pracę lub o~dzieło), płaca minimalna czy ustalanie wysokości zasiłków dla bezrobotnych. 

W~poniższej pracy zostanie przedstawiony bayesowski model ekonometryczny, który wyjaśni, jak silnie wpływają poszczególne czynniki na wysokość stopy bezrobocia w~krajach Unii Europejskiej w~2013 roku. Zostaną wykorzystane ogólnodostępne dane ze stron internetowych Eurostatu i~OECD, dotyczące różnych wskaźników makroekonomicznych oraz wyniki analizy przeprowadzonej przez panią Desiree Tercek z~John Carroll University pt.: \textit{Determinants of European and United States Unemployment}, które stanowią podstawę analizy a~priori (w~pracy określenie \textit{artykuł} będzie się zawsze odnosiło właśnie do tego artykułu).

Pracę wykonano w~języku R oraz dostępnej w~nim bibliotece \textit{knitr}, która umożliwia jednoczesną pracę w~językach R oraz \LaTeX.

\section{Zbiór danych}

\subsection{Opis słowny danych}

Dane niezbędne do przeprowadzenia analizy zostały wybrane na podstawie \textit{artykułu} (wybrane zmienne objaśniające w~opisanym w~\textit{artykule} modelu w~istotny sposób wpłynęły na wartość zmiennej objaśnianej).

W~analizie wykorzystano następujące wskaźniki ekonomiczne (w~nawiasach znajduje się skrót zmiennej wykorzystywany w~skryptach R oraz angielska nazwa zmiennej pochodząca z~artykułu):
\begin{enumerate}
    \item stopa bezrobocie (ur - unemployment rate)\footnote{http://ec.europa.eu/eurostat}
    \item liczba pracowników pracujących na mniej niż cały etap (pte - part time employment)\footnotemark[\value{footnote}] (co ciekawe, dane dotyczące zatrudnionych na mniej niż cały etat są dostępne również na stronie OECD i~znacznie różnią się od tych prezentowanych przez Eurostat - wybór danych z~Eurostatu nie był podparty racjonalnymi przesłankami, ponieważ założono, że dane pochodzące z~obu tych stron są tak samo dobrej jakości i~nie ma znaczenia, które zostaną wykorzystane)
    \item średnia liczba przepracowanych godzin rocznie przez pojedynczego pracownika (aah - average annual hours actually worked per worker)\footnote{http://www.data.oecd.org} 
    \item wydatki państwa na zasiłki dla bezrobotnych - jako procent PKB (pue - public unemployment social expenditure)\footnotemark[\value{footnote}] 
    \item wydatki socjalne państwa - jako procent PKB (pse - public total social expenditure)\footnotemark[\value{footnote}] 
    \item wskażnik ochrony pracowników przed zwolnieniami (sor - strictness of employment protection \dywiz\ individual and collective dismissals)\footnote{http://stats.oecd.org}
    \item wskaźnik ochrony pracowników zatrudnianych na kontrakty (sot - strictness of employment protection \dywiz\ temporary contracts)\footnotemark[\value{footnote}] 
    \item gęstość związków zawodowych - odsetek pracowników zrzeszonych w~związkach zawodowych (tud - trade union density)\footnotemark[\value{footnote}] 

\end{enumerate}

Niestety dane znajdujące się na stronach internetowych OECD oraz Eurostatu nie były kompletne. Z~tej przyczyny do analizy wykorzystano dane z~2013 roku (były to najnowsze kompletne dane). Poza tym nie wykorzystano informacji dotyczących Chorwacji, Cypru, Litwy, Łotwy, Malty, Rumunii i~Słowacji. Wartości zmiennej \textit{tud - gęstość związków zawodowych} dla Luksemburgu, Polski i~Portugalii pochodzą z~2012 roku (założono, że wartość tej zmiennej nie zmieniła się znacznie w~latach 2012-2013). Brak wartości zmiennej \textit{pte - part time employment} dla Francji w~2013r. został zastąpiony wartością z~2014 roku.

\subsection{Opis statystyczny danych}

<<echo=F>>=
setwd('/home/tomek/Documents/szkola/MIESI/IV_sem/Ekonometria_bayesowska/projekt')
d <- read.table('data.csv', sep=';', dec=',', header=T)
@

W~tabeli \ref{tab:zbiorDanych} przedstawiono zbiór danych.

<<echo=F, results='asis'>>=
library(xtable)
dxt <- xtable(d, digits=1, caption='Zbiór danych', label='tab:zbiorDanych')
print(dxt)
@

Dane dotyczą \(\Sexpr{nrow(d)}\) państw Unii Europejskiej. Zmienną objaśnianą charakteryzują statystyki przedstawione w~tabeli \ref{tab:daneStatystyki}.

<<echo=F, results='asis'>>=
library(psych)
library(xtable)
t <- xtable(as.data.frame(describe(d$ur)), caption='Podstawowe statystyki zmiennej objaśnianej', label='tab:daneStatystyki')
print(t, rotate.colnames=T)
@
\vspace{3mm}
Ze statystyk przedstawionych w~tabeli \ref{tab:daneStatystyki} wynika, że średnia stopa bezrobocia w~krajach Unii Europejskiej wynosi \(\Sexpr{describe(d$ur)$mean}\) przy - mogłoby się wydawać - dosyć dużym odchyleniu standardowym wynoszącym \(\Sexpr{round(describe(d$ur)$sd, 2)}\). Wstępnie można wysnuć wniosek, że Unia Europejska jest dosyć silnie zróżnicowana pod względem jakości życia.

Dla uplastycznienia zmiennej objaśnianej zostaje ona przedstawiona na rysunku \ref{fig:wizualizacjaDanych}.

\begin{figure}[H]
    \begin{subfigure}{0.5\textwidth}
<<echo=FALSE, message=FALSE, fig.height=3.5, fig.width=3.5, fig.pos='H'>>= 
library(grid)
library(rworldmap)
library(ggplot2)
pHist <- ggplot(d, aes(x=ur)) + ylab('gestosc') + xlab('stopa bezrobocia')
pHist <- pHist + geom_histogram(aes(y = ..density..), binwidth=density(d$ur)$bw)
pHist <- pHist + geom_density(fill="green", alpha = 0.2)
pHist <- pHist + theme_bw()
pHist <- pHist + ggtitle('Histogram') 
pHist <- pHist + theme(plot.title = element_text(hjust = 0.5))
plot(pHist)
@
\caption{Histogram oraz przybliżona gęstość} \label{fig:histogram}
\end{subfigure}
\begin{subfigure}{0.5\textwidth}
<<echo=FALSE, message=FALSE, fig.height=3.5, fig.width=3.5, fig.pos='H'>>= 
worldMap <- getMap()
m <- getMap()
cs <- d$country
cs[cs == 'Czech Republic'] <- 'Czech Rep.'
indEU <- which(m$NAME%in%cs)
coords <- lapply(indEU, function(i){
                     df <- data.frame(m@polygons[[i]]@Polygons[[1]]@coords)
                     df$region =as.character(m$NAME[i])
                     colnames(df) <- list("long", "lat", "region")
                     return(df)
})
coords <- do.call("rbind", coords)
EUtable<- data.frame(country = cs, value = d$ur)
coords$value <- EUtable$value[match(coords$region, EUtable$country)]
pMap <- ggplot() + geom_polygon(data = coords, 
                                aes(x = long, y = lat, 
                                    group = region, fill = value),
                                colour = "black", size = 0.1)
pMap <- pMap + coord_map(xlim = c(-13, 35),  ylim = c(32, 71))
pMap <- pMap + scale_fill_gradient(name = "Stopa\nbezrobocia", low = "#009933", 
                                   high = "#ffff00", na.value = "grey50")
pMap <- pMap + theme(axis.text.x = element_blank(),
                     axis.text.y = element_blank(), axis.ticks.x = element_blank(),
                     axis.ticks.y = element_blank(), axis.title = element_blank(),
                     plot.margin = unit(0 * c(-1.5, -1.5, -1.5, -1.5), "lines"))
pMap <- pMap + theme_bw()
pMap <- pMap + ggtitle('Mapa') + theme(plot.title = element_text(hjust = 0.5))
pMap <- pMap + xlab('dlugosc geograficzna') + ylab('szerokosc geograficzna')
plot(pMap)
@
\caption{Mapa państw ujętych w~analizie} \label{fig:mapa}
\end{subfigure}
\caption{Wizualizacja stopy bezrobocia w~krajach Unii Europejskiej} \label{fig:wizualizacjaDanych}
\end{figure}
Na histogramie widoczne jest pewne podobieństwo do rozkładu normalnego. Zaburza je wysoki poziom bezrobocia w~Hipszanii i~Grecji (po ponad 20\% - jest to widoczne na mapie) oraz brak obserwacji ujemnych (stopa bezrobocia z~definicji jest nieujemna, więc rozkład jest ucięty w~zerze). Gdyby pominąć te dwa zjawiska oraz gdyby dysponowano większą próbą, histogram najpewniej jednoznacznie by wskazywał, że zmienna jest zbieżna do rozkładu normalnego. 

\section{Wykorzystany model}

Do badania stopy bezrobocia w~poszczególnych krajach Unii Europejskiej można wykorzystać model panelowy, który uwzględni informacje z~poprzednich kilkunastu lat (lub nawet kwartałów). Dzięki temu można uzyskać \textit{lepsze} oszacowania ze względu na większą próbę\footnote{Próbowałem stworzyć bayesowski model panelowy na tych samych danych (oczywiście z~dodatkowym wymiarem czasu), który mógłbym oszacować za pomocą funkcji HMMpanelFE z~pakietu MCMCpack, jednak korzystając z~funkcji BayesFactor w~tym pakiecie nie udało mi się uzyskać wartości czynnika Bayesa (wyskakiwał error). Stając przed dylematem: analiza danych panelowych bez czynnika Bayesa lub danych przekrojowych z~czynnikiem, wybrałem drugą opcję.}. Mankamentem takiego podejścia jest odrzucenie wyników badań, które zostały już przeprowadzone na temat determinant stopy bezrobocia.

Charakterystyczna dla modelowania bayesowskiego jest możliwość połączenia wiedzy eksperckiej z~dostępnymi danymi w~jeden spójny model. Wiedza ekspercka, określana jako \textit{a~priori}, jest to pewne domniemanie dotyczące rokładów parametrów modelu (w~szczególności ich wartości oczekiwanych, wariancji i~korelacji między nimi), które wynika z~doświadczenia badacza lub innych przesłanek, których nie sposób potraktować jako dane ilościowe. Z~kolei dostępne dane są interpretowane w~następujący sposób: jakie jest prawdopodobieństwo wylosowania właśnie takich wartości, przy różnych wartościach parametrów. Taka probabilistyczna interpretacja danych nazywana jest \textit{gęstością danych}. Połączenie gęstości danych i~informacji a~priori pozwala na uzyskanie oczasowań parametrów \textit{a~posteriori}, co przy wykorzystaniu twierdzenia Bayesa można zapisać w~następujący sposób:
\begin{equation}
    f(\theta|y)\propto f(y|\theta)\cdot f(\theta) 
    \label{eq:aPosteriori}
\end{equation}
Warto zwrócić uwagę, że nie jest to równość, jednak pominięcie elementu skalującego nie wpłynie na interpretację parametrów a~posteriori. 

\subsection{A~priori}
W~modelu wykorzystanym w~poniższej analizie założono a~priori (zgodnie z~\textit{artykułem}), że stopa bezrobocia jest liniową kombinacją zmiennych objaśniających. W~związku z~tym postać funkcyjna modelu przedstawia się następująco: 
\begin{equation}
    ur_i=\beta_0+\beta_1pte_{1,i}+\beta_2aah_{2,i}+\beta_3pue_{3,i}+\beta_4pse_{4,i}+\beta_5sor_{5,i}+\beta_6sot_{6,i}+\beta_7tud_{7,i}+\varepsilon_i
\end{equation}
Ponadto przyjęto, że składnik losowy oraz parametry mają rozkłady normalne o~wartościach oczekiwanych równych odpowiednio: 0 i~oszacowaniom parametrów w~\textit{artykule} oraz wariancjach $\sigma^2$ i~błędom standardowym oszacowań parametrów podniesionym do kwadratu (dane z~\textit{artykułu}). Aby opisać rozkład wariancji składnika losowego, posułożono się zmienną pomocniczą $h$, którą można w~jednoznaczny sposób przekształcić w~$\sigma^2$ ($h^{-1}=\sigma^2$). Założono, że ma ona rozkład gamma. Powyższe informacje można zapisać w~następującej formie (uwzględniono, że $h$ występuje w~rozkładzie bet jako parametr, co oznacza, że rozkład bet jest zależny od wartości $h$):

\begin{equation}
    \boldsymbol{\beta}|h\sim \boldsymbol{N}(\underline{\boldsymbol{\beta}}, h^{-1}\underline{\boldsymbol{U}})
\end{equation}
\begin{equation}
    h\sim G(\underline{s}^{-2}, \underline{\nu})
\end{equation}
co można zapisać jako jeden rozkład normalny\dywiz gamma:
\begin{equation}
    \boldsymbol{\beta}, h\sim \boldsymbol{N}G(\boldsymbol{\beta}, h^{-1}\underline{\boldsymbol{U}},\underline{s}^{-2}, \underline{\nu})
\end{equation}
gdzie $\underline{\boldsymbol{\beta}}=[0, 0, 0.015, 4.201, 0.603, -3.623, -2.981, 0.117]^{T}$, natomiast 

\noindent
$diag(h^{-1}\underline{\boldsymbol{U}})=[500,10,0.000003,2.374946,0.015331,0.584965,0.299619,0.000705]$.
\\~\\
\indent
Wariancje stałej i~zmiennej $pte$ przyjęto jako nieznane a~priori, ponieważ w~\textit{artykule} stała w~modelu była nieistotna statystycznie, natomiast zarówno oszacowanie, jak i~wariancja zmiennej $pte$ były bardzo bliskie zera (w~artykule zmienna $pte$ była wyrażona w~liczbie pracowników, a~nie w~postaci odsetka osób pracujących nie na cały etat wśród wszystkich pracujących. Wydaje się to być niezbyt dobrym pomysłem, ponieważ kraje różnią się liczbą ludności, a~zmienna objaśniana jest wyrażona jako odsetek.) Wariancja a~priori może wydawać się bardzo niska - wynika to z~faktu, że same oszacowania paramatrów są małymi (bliskimi zera) wartościami, a~ich błędy (odchylenia) standardowe są mniejsze od 1 - te podniesione do kwadratu (w~celu otrzymania wariancji) dają bardzo małe wartości. Ponadto, z~uwagi na brak informacji w~\textit{artykule} na temat sumy kwadratów reszt i, co za tym idzie, wariancji składnika losowego, zostaje ona przyjęta jako 1 (arbitralnie, z~uwagi na łatwość obliczeń). W~rezultacie parametry rozkładu a~prio wariancji składnika losowego wynoszą: $\underline{s}^{-2}=1$ oraz $\underline{v}=92$ (wielkość próby w~badaniu w~\textit{artykule}). Przy tym wartość oczekiwana rozkładu gamma wynosi $s^{-2}=1$, więc przyjęto, że we wzorze na wariancje a~priori parametrów beta $\underline{\boldsymbol{U}}=h^{-1}\underline{\boldsymbol{U}}$ (umożliwi to wykorzystanie funkcji MCMCregress z~pakietu MCMC, która zakłada niezależność rozkładów bet i~$\sigma^2$, przez co wariancja bet jest zdefiniowana po prostu jako $\underline{\boldsymbol{U}}$, a~nie jako $h^{-1}\underline{\boldsymbol{U}}$).

Elementy macierzy $h^{-1}\underline{\boldsymbol{U}}$ leżące poza przekątną (kowariancje parametrów) zostały przyjęte a~priori jako zerowe, gdyż nie ma podstaw, by sądzić inaczej (w~\textit{artykule} nie znalazła się informacja o~kowariancjach oszacowań parametrów).

\subsection{Gęstość danych}

Obliczenie gęstości danych jest konieczne, aby uzyskać rozkład a~posteriori parametrów. Sprowadza się ono do obliczenia funkcji wiarygodności zbioru danych - założono, że wartości stopy bezrobocia są niezależne pomiędzy poszczególnymi krajami i~wynikają jedynie z~wartości zmiennych objaśniających oraz składnika losowego (który z~założenia jest $IID$). To założenie może budzić kontrowersje z~uwagi na fakt, że na terenie Unii Europejskiej siła robocza może przemieszczać się bez ograniczeń, a~więc zmniejszenie się bezrobocia w~jednym kraju spowodowane emigracją bezrobotnych (na przykład z~Polski) może spowodować większe bezrobocie w~Wielkiej Brytanii (brytyjscy pracodawcy chętniej zatrudniają tanich pracowników z~Polski niż Brytyjczyków, którzy przez to trafiają na bezrobocie). Co więcej, na rysunku \ref{fig:mapa} widoczne jest, że bardzo wysokie bezrobocie dotyka krajów leżących na południu (Hiszpania, Grecja), co może być związane z~klimatem. Być może odpowiednie byłoby zastosowanie tutaj modelu uwzględniającego te wpływy, na przykład ekonometrycznego modelu przestrzennego.

Zgodnie z~założeniem dotyczącym wzajemnej niezależności od siebie poszczególnych obserwacji zmiennej objaśnianej, gęstość danych można zapisać jako iloczyn funkcji gęstości każdej obserwacji:
\begin{equation}
    f(ur|\boldsymbol{\beta}, h)=\prod_{i=1}^{20} f(ur_i|\boldsymbol{\beta}, h) = \frac{h^{10}}{(2\pi)^{10}}exp[-\frac{h}{2}\sum\limits_{i=1}^{20}(ur_i - \boldsymbol{x}_i^T\boldsymbol{\beta})^2]
\end{equation}

\subsection{A~posteriori}

Obliczenie wartości a~posteriori jest w~przypadku przedstawionego modelu możliwe do wykonania analitycznie, stosując wzór \ref{eq:aPosteriori}. Do obliczenia rozkładów a~posteriori wykorzystano następujące wzory\footnote{wzory pochodzą z~wykładu 4 \textit{Bayesowska analiza modelu regresji liniowej wielu zmiennych}}
\begin{equation}
    \overline{\boldsymbol{\beta}}=(\underline{\boldsymbol{U}}^{-1}+\boldsymbol{X}^T\boldsymbol{X})^{-1}(\underline{\boldsymbol{U}}^{-1}\underline{\boldsymbol{\beta}}+\boldsymbol{X}^T\boldsymbol{X}\hat{\boldsymbol{\beta}})
\end{equation}
\begin{equation}
    \overline{\boldsymbol{U}}=(\underline{\boldsymbol{U}}^{-1}+\boldsymbol{X}^T\boldsymbol{X})^{-1}
\end{equation}
\begin{equation}
    \overline{\nu}=\underline{\nu}+N
\end{equation}
\begin{equation}
    \overline{\nu s}^2=\hat{\nu}\hat{s}^2+\underline{\nu s}^2+(\hat{\boldsymbol{\beta}}-\underline{\boldsymbol{\beta}})^T[\underline{\boldsymbol{U}}+(\boldsymbol{X}^T\boldsymbol{X})^{-1}]^{-1}(\hat{\boldsymbol{\beta}}-\underline{\boldsymbol{\beta}})
\end{equation}

Zauważono, że rozkład a~posteriori jest również rozkładem normalnym\dywiz gamma, co oznacza, że jest on sprzężony do rozkładu a~priori. Aby móc intuicyjnie zinterpretować uzyskane rozkłady a~posteriori, należy uniezależnić rozkłady bet od rozkładu $h$ poprzez całkowanie uzyskanego rozkładu a~posteriori po $h$ (innymi słowy oznacza to policzenie gęstości brzegowej rozkładu). W~rezultacie z~początkowego rozkładu bet (wielowymiarowego rozkładu normalnego) powstaje wielowymiarowy rozkład t\dywiz Studenta.

Każdy z~rozkładów bet a~posteriori ma rozkład t\dywiz Studenta, który można zapisać jako:
\begin{equation}
    \beta_i|y\sim t(\overline{\beta}_i, \overline{s}^2 \overline{U}_{i,i}, \overline{v}_i)
\end{equation}

Na rysunku \ref{fig:wykresy} przedstawiono rozkłady a~posteriori bet (niezależne od rozkładu $h$) zestawione z~rozkładami a~priori. 

\textit{W~modelach bayesowskich równanie opisujące zmienną objaśnianą nie zawsze jest liniowe, a~parametry nie zawsze są zbieżne do typowego rozkładu (jakimi są na przykład rozkład normalny lub gamma). W~takich sytuacjach jednym ze sposobów uzyskania rozkładu a~posteriori jest zastosowanie metody numerycznej klasy MCMC (Markov Chain Monte Carlo), które umożliwiają n\dywiz krotne losowanie z~rozkładu a~posteriori, mając dane rozkłady a~priori i~gęstość danych. Jednym z~takich algorytmów jest próbnik Gibbsa. W~R dostępna jest funkcja MCMCregress z~bibliotece MCMCpack, która umożliwia zastosowanie próbnika Gibbsa do przybliżenia rozkładu a~posteriori parametrów modelu liniowego o~analogicznej specyfikacji do przedstawionego powyżej, z~jednym wyjątkiem: założono a~priori, że rozkłady bet oraz wariancji składnika losowego są od siebie niezależne. W~rezultacie rozkłady bet a~posteriori będą miały po prostu rozkłady normalne - nie będzie konieczne liczenie gęstości brzegowej. Pomimo to na wykresie \ref{fig:wykresy} przedstawiono rozkłady parametrów a~posteriori szacowane za pomocą MCMCregress, aby zweryfikować, na ile założenie o~zależności bet od $\sigma^2$ ma wpływa na rozkład a~posteriori oraz na ile skuteczny jest próbnik Gibbsa - można to sprawdzic porównująć wartości MCMC z~obliczonymi analitycznie.}

\section{Ocena jakości modelu}

\subsection{Porównanie a~priori z~a~posteriori}

Celem modelowania bayesowskiego jest oczywiście uzyskanie modelu, który \textit{dobrze} opisuje badaną zmienną, jednak właściwie niemożliwe jest znalezienie obiektywnej miary, która odpowie, jak \textit{dobry} jest model. W~takiej sytuacji za sukces analityka można uznać sytuację, kiedy w~wyniku analizy parametry a~posteriori maja mniejszą wariancję niz a~priori. 

\textit{W~tym miejscu wprowadzono poprawkę do rozkładów a~priori, co jest niezgodne ze sztuką tworzenia modelu bayesowskiego. Wynikało to z~uzyskania modelu, w~którym w~5 na 8 zmiennych wariancja a~posteriori była większa niż a~priori, czego przyczyną mogło być przyjęcie zbyt małych wariancji a~priori. Z~kolei przyczyną dla przyjęcia tak małych wartości była intuicja autora pracy, która najwidoczniej - z~uwagi na małe doświadczenie w~tworzeniu modelu bayesowskich - zawiodła. Nowa wariancja a~priori jest dwukrotnie wyższa od wcześniej przyjetej i~od tej chwili analiza będzie oparta o~nowe wartości wariancji.}

Na rysunku \ref{fig:wykresy} widoczne jest, że dla wszystkich zmiennych (z~wyjątkiem aah) doszło do zawężenia wariancji po wprowadzeniu do modelu danych, co można uznać za sukces. Nie jest to zaskakujące dla zmiennych intercept oraz pte, gdzie a~priori celowo przyjęto wysoką wartość wariancji (w~ten sposób niemal całość informacji dotyczącej rozkładu tych parametrów a~posteriori pochodzi z~danych). Widoczne jest również podobieństwo rozkładu a~priori do~a~posteriori parametru zmiennej pse (wydatki państwa na opiekę społeczną jako \% PKB). Oznacza to, że rozkład a~priori był podobny do tego zawartego w~danych. Dla zmiennych pue (zasiłki dla bezrobotnych jako \% PKB), sor (ochrona pracowników stałych), sot (ochrona pracowników na kontrakty) oraz tud (gęstość związków zawodowych) widoczne jest znaczne zmniejszenie wariancji. Zmienne sor oraz sot (ochrona pracowników stałych i~na kontraktach) przestały w~znaczący sposób wpływać na stopę bezrobocia, ponieważ wartości oczekiwane ich parametrów znacznie zbliżyły się do zera. 

\begin{figure}[H]
    \captionsetup{justification=centering}
<<echo=F, message=F, fig.height=5, fig.width=7>>= 
# funkcja z~zajęć
density.t <- function(b, m, Scale, df) {
    dimen <- length(m)
    d.t <- ((pi * df) ^ (-dimen / 2)) *
        gamma(dimen / 2) / beta(df / 2, dimen / 2) * 
        det(Scale) ^ (-0.5) * ((1 + 1 / df * t(b - m) %*% 
                                solve(Scale) %*% (b - m)) ^ (-(df + dimen) / 2))
        return(d.t)
}

# dane
y <- matrix(d$ur, ncol=1)
X <- d
X[c('country', 'ur')] <- NULL
X <- cbind(1, as.matrix(X))
colnames(X)[1] <- 'intercept'
BetaEst <- solve(t(X) %*% X)  %*% t(X) %*% y 
rEst <- y - X %*% BetaEst
vEst <- nrow(X) - ncol(X)
s2Est <- sum(rEst^2) / vEst

# priori
BetaPrio <- c(0, 0, 0.015, 4.201, 0.603, -3.623, -2.981, 0.117)
UPrio <- diag(c(500,10,0.000003,2.374946,0.015331,0.584965,0.299619,0.000705)*2)
vPrio <- 92
s2Prio <- 1

# posteriori
BetaPost <- solve(solve(UPrio) + t(X) %*% X) %*% (solve(UPrio) %*% BetaPrio + t(X) %*% X %*% BetaEst)
UPost <- solve(solve(UPrio) + t(X) %*% X)
vPost <- vPrio + nrow(d)
vs2Post <- vPrio * 1 / s2Prio +  # dopasowany kod z~zajęć
    vEst * s2Est +
        t(BetaEst - BetaPrio) %*% 
        solve(UPrio + solve(t(X) %*% X)) %*% (BetaEst - BetaPrio)
    s2Post <- 1 / (vs2Post / vPost)

    # mcmc
    dd <- d
    dd['country'] <- NULL
    #c0/2 is the shape parameter for the inverse Gamma prior on
    #          sigma^2 (the variance of the disturbances).
    a <- vPrio / 2
    b <- vPrio * s2Prio / 2
    library(MCMCpack)
    m1 <- MCMCregress(ur ~ .,
                      data=dd,
                      b0=BetaPrio,
                      B0=diag(solve(UPrio)),
                      c0=a * 2,
                      d0=b * 2,
                      marginal.likelihood="Chib95")

    # rysowanie wykresów
    # przygotowanie danych
    mdf <- as.data.frame(m1)
    names(mdf)[1] <- 'intercept'
    mdf$sigma2 <- NULL

    names(BetaPrio) <- names(BetaPost) <- names(mdf)
    UPrio <- diag(UPrio)
    UPost <- diag(UPost)
    names(UPrio) <- names(UPost) <- names(mdf)

    library(ggplot2)
    library(reshape2)
    drawPlot <- function(dataMCMC, cvar) {
        mcmcResult <- density(as.numeric(dataMCMC[cvar][[1]]))
        yMCMC <- mcmcResult$y
        x <- mcmcResult$x
        yPrio <- vapply(x, density.t, 1, m=BetaPrio[cvar], Scale=as.matrix(UPrio[cvar]/s2Prio), df=vPrio)
        yPost <- vapply(x, density.t, 1, m=BetaPost[cvar], Scale=as.matrix(UPost[cvar]/s2Post), df=vPost)
        data.df <- data.frame(x=x, yPrio=yPrio, yPost=yPost, yMCMC=yMCMC)
        data.compl <- melt(data.df, id='x')
        p <- ggplot(data=data.compl, aes(x=x, y=value, colour=variable)) +
            geom_line() +
            xlab(cvar) + ylab(NULL) +
            theme_bw() +
            scale_colour_manual(values=c('#FF3333', '#3399FF', '#00994C'),
                                name='rozklad',
                                labels=c('a priori',
                                         'a posteriori - analitycznie',
                                         'a posteriori - Gibbs'))
            return(p)
    }
    plots <- lapply(names(mdf), drawPlot, dataMCMC=mdf)
    library(gridExtra)
    g_legend <- function(a.gplot) {
        tmp <- ggplot_gtable(ggplot_build(a.gplot))
        leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box")
        legend <- tmp$grobs[[leg]]
        return(legend)}
    mylegend <- g_legend(plots[[1]])  
    # co ciekawe, tutaj sapply już nie chce działać
    grid.arrange(top=textGrob('Rozklady a priori i a posteriori parametrow'),
                 plots[[1]] + theme(legend.position='none'), 
                 plots[[2]] + theme(legend.position='none'), 
                 plots[[3]] + theme(legend.position='none'), 
                 plots[[4]] + theme(legend.position='none'), 
                 plots[[5]] + theme(legend.position='none'), 
                 plots[[6]] + theme(legend.position='none'), 
                 plots[[7]] + theme(legend.position='none'), 
                 plots[[8]] + theme(legend.position='none'), 
                 mylegend)
@
\caption{Porównanie rozkładów a~priori oraz a~posteriori uzyskanego analitycznie i~za pomocą próbnika Gibbsa} \label{fig:wykresy}
\end{figure}

\begin{wrapfigure}{r}{3.1in}
<<echo=FALSE, message=FALSE, fig.height=3, fig.width=3, fig.pos='H'>>= 
X <- d
rownames(X) <- d$country
X$country <- NULL
library(corrplot)
corrplot.mixed(cor(X), tl.cex=0.75, number.cex=0.6,
               title='Korelacje pomiedzy zmiennymi',
               mar=c(0, 0, 1, 0), font.main=1, family='Helvetica',
               cex.main=0.9)
@
\caption{Korelacje pomiędzy zmiennymi}\label{fig:korelacje}
\end{wrapfigure}

Ciekawa jest również zmiana kierunku wpływu zmiennej tud (gęstość związków zawodowych) z~dodatniego na ujemny. Model wskazuje, że im więcej pracowników zrzeszonych jest w~związki zawodowe, tym niższe jest bezrobocie (relacja przyczynowo \dywiz\ skutkowa pomiędzy zmiennymi tud i~ur (stopa bezrobocia) nie jest oczywista: z~jednej strony wysokie bezrobocie może wiązać się z~dużym ryzykiem utraty pracy, co zachęca do uczestnictwa w~związkach, z~drugiej - wysoki odsetek pracowników w~związkach utrudnia zwolnienia). 

Nietypowe zachowanie zmiennej aah (zwiększenie wariancji a~posteriori w~porównaniu do a~priori) może wynikać z~występowania silnych korelacji pomiędzy zmiennymi. Na rysunku \ref{fig:korelacje} widoczna jest dosyć silna ujemna korelacja pomiędzy zmiennymi pte (odsetek zatrudnionych nie na cały etat) oraz aah (średnia liczba przepracowanych godzin rocznie przez pracownika), co jest zresztą dosyć oczywiste, gdyż osoby pracujące na mniej niż cały etat pracują krócej. Przy tak silnej korelacji można zastanowić się nad wykluczeniem którejś ze zmiennych z~modelu lub policzyć dodatkowy wskaźnik, który mógłby uzasadnić taką decyzję, np. VIF (czynnik inflacji wariancji).

Wyniki uzyskane za pomocą próbnika Gibbsa są dla większości zmiennych podobne do rozwiązania analitycznego, jednak za każdym razem ich wartość oczekiwana jest bliższa wartości oczekiwanej a~priori. Dla większości parametrów próbnik Gibbsa wypadł zadowalająco, jednak dla zmiennych sor i~sot otrzymane wartości oczekiwane są bardzo bliskie zera, co wskazuje na niemal niezauważalny wpływ tych zmiennych na stopę bezrobocia i~może sugerować usunięcie tych zmiennych z~modelu.

\subsection{Czynnik Bayesa}

Czynnik Bayesa jest miarą, która pozwala na porównanie ze sobą dwóch modeli i~ocenę, który z~nich jest \textit{lepszy}. Definiuje się go jako:

\begin{equation}
    BF^{(i,j)}=\frac{P(\boldsymbol{y}|M^{(i)})}{P(\boldsymbol{y}|M^{(j)})}=PO^{(i,j)}\frac{P(M^{(i)})}{P(M^{(j)})}
\end{equation}
czyli jest to iloraz szans a~posteriori (szansa na otrzymanie właśnie takich rozkładów parametrów przy określonym $\boldsymbol{y}$) pomnożony przez iloraz szans a~priori (czyli ocenę a~priori, który z~modeli jest \textit{lepszy}). Warto zwrócić uwagę, że w~przypadku przyjęcia równych wartości szans a~priori dla obu modeli (tzw. nieinformacyjnego a~priori), czynnik Bayesa jest równy ilorazowi a~posteriori. 

Czynnik Bayesa może być stosowany do porównywania dowolnych dwóch modeli wyjaśniających tą samą zmienną. W~szczególności jest on przydatny w~sytuacji, kiedy porównujemy dwa modele, z~których jeden zawiera pewien zestaw zmiennych, a~drugi ten sam zestaw pomniejszony o~jedną zmienną. Uzyskana wtedy miara może być interpretowana analogicznie do statystyki t\dywiz Studenta, badającej istotność zmiennej w~modelu w~analizie klasycznej. 

W~analizowanym zagadnieniu czynnik Bayesa może zostać wykorzystany w~celu zweryfikowania przydatności w~modelu poszczególnych zmiennych: jeżeli okaże się, że model bez danej zmiennej jest \textit{lepszy}, należy usunąć taka zmienną. Przyjęto nieinformacyjne a~priori. 

<<echo=F, results='asis'>>=
# czynnik Bayesa analitycznie
countMarginalDensity <- function(zbednaZmienna, BetaPrio, UPrio, vPrio, s2Prio, d) {
    y <- matrix(d$ur, ncol=1)
    X <- d
    X[c('country', 'ur')] <- NULL
    X <- cbind(1, as.matrix(X))

    vs2Prio <- vPrio * s2Prio
    # przygotowanie a~priori
    if (zbednaZmienna != 0) {
        BetaPrio <- BetaPrio[-zbednaZmienna]
        UPrio  <- UPrio[-zbednaZmienna, -zbednaZmienna]
        X <- X[, -zbednaZmienna]}

    # dane
    colnames(X)[1] <- 'intercept'
    BetaEst <- solve(t(X) %*% X)  %*% t(X) %*% y 
    rEst <- y - X %*% BetaEst
    vEst <- nrow(X) - ncol(X)
    s2Est <- sum(rEst^2) / vEst

    # a~posteriori
    BetaPost <- solve(solve(UPrio) + t(X) %*% X) %*% (solve(UPrio) %*% BetaPrio + t(X) %*% X %*% BetaEst)
    UPost <- solve(solve(UPrio) + t(X) %*% X)
    vPost <- vPrio + nrow(X)
    vs2Post <- vPrio * 1 / s2Prio +  # dopasowany kod z~zajęć
        vEst * s2Est +
            t(BetaEst - BetaPrio) %*% 
            solve(UPrio + solve(t(X) %*% X)) %*% (BetaEst - BetaPrio)
        s2Post <- 1 / (vs2Post / vPost)

        # gęstość brzegowa a~posteriori
        licznik <- det(UPost) ^ (1/2) * gamma(vPost / 2) * vs2Post ^ (-vPost / 2)  
        mianownik <- pi ^ (nrow(X) / 2) * det(UPrio) ^ (1 / 2) * gamma(vPrio / 2) * vs2Prio ^ (-vPrio / 2)
        return(licznik / mianownik)}

MDenss <- sapply(0:8, countMarginalDensity, BetaPrio=BetaPrio, UPrio=diag(UPrio), vPrio, s2Prio=s2Prio, d=d)
BFs <- outer(MDenss, MDenss, FUN=function(x, y) {x / y})
BFs <- round(log(BFs) / log(10), 1)
BFs <- BFs[-2,-2]
colnames(BFs) <- rownames(BFs) <-  c('full', names(d)[-1:-2])


# czynnik Bayesa MCMC
dd <- d
dd$country <- NULL
a <- vPrio / 2
b <- vPrio * s2Prio / 2
library(MCMCpack)
countMCMCregress <- function(zbednaZmienna, dd, BetaPrio, UPrio, B0, a, b) {

    if (zbednaZmienna != 0) {
        dd <- dd[-zbednaZmienna]
        BetaPrio <- BetaPrio[-zbednaZmienna]
        UPrio <- UPrio[-zbednaZmienna,-zbednaZmienna]}

    md <- MCMCregress(ur~.,
                      data=dd,
                      bo=BetaPrio,
                      B0=diag(solve(UPrio)),
                      c0=a * 2,
                      d0= b * 2,
                      marginal.likelihood='Chib95')
    return(md)}

ms <- sapply(c(0, 2:8), countMCMCregress , dd=dd, BetaPrio=BetaPrio, UPrio=diag(UPrio), a=a, b=b)
BFmcmc <- BayesFactor(ms[[1]], ms[[2]], ms[[3]], ms[[4]], ms[[5]], ms[[6]], ms[[7]], ms[[8]]) 
BFmcmcMatrix <- round(log(BFmcmc$BF.mat) / log(10), 1)
colnames(BFmcmcMatrix) <- rownames(BFmcmcMatrix) <- c('full', names(dd)[-1])
@

\begin{figure}[H]
    \begin{subfigure}{0.5\textwidth}
<<echo=FALSE, message=FALSE, fig.height=4, fig.width=4, fig.pos='H'>>= 
library(reshape2)
library(RColorBrewer)
m <- melt(BFs)
m <- m[order(m$Var2, decreasing=T),]
m <- m[order(m$Var1, decreasing=T),]
rownames(m) <- 1:64
myPalette <- colorRampPalette(rev(brewer.pal(11, "Spectral")), space="Lab")

pB1 <- ggplot(m,  aes(x = Var1, y = Var2, fill = value))
pB1 <- pB1 + xlab('Model 1 (licznik)') + ylab('Model 2 (mianownik)')
pB1 <- pB1 + geom_tile()
pB1 <- pB1 + geom_text(aes(label = round(value, 1)), size=3)
pB1 <- pB1 + scale_fill_gradientn(colours = myPalette(100), name='potega\nliczby 10')
pB1 <- pB1 + scale_x_discrete(expand = c(0, 0))
pB1 <- pB1 + scale_y_discrete(expand = c(0, 0))
pB1 <- pB1 + theme_bw()
pB1 <- pB1 + ggtitle('Czynniki Bayesa (analitycznie)')
pB1 <- pB1 + coord_equal()
pB1 <- pB1 + theme(legend.position=c(0.5, -0.25),
                   legend.direction='horizontal',
                   plot.margin = unit(c(0,0,1.5,0), "cm"),
                   plot.title=element_text(hjust=0.5))
pB1 <- pB1 + guides(colour = guide_legend(title.hjust = 0.5))
plot(pB1)
@
\caption{Czynniki Bayesa policzone analitycznie} \label{fig:BayesA}
\end{subfigure}
\begin{subfigure}{0.5\textwidth}
<<echo=FALSE, message=FALSE, fig.height=4, fig.width=4, fig.pos='H'>>= 
m <- melt(BFmcmcMatrix)
m <- m[order(m$Var2, decreasing=T),]
m <- m[order(m$Var1, decreasing=T),]
rownames(m) <- 1:64
myPalette <- colorRampPalette(rev(brewer.pal(11, "Spectral")), space="Lab")

pB2 <- ggplot(m,  aes(x = Var1, y = Var2, fill = value))
pB2 <- pB2 + xlab('Model 1 (licznik)') + ylab('Model 2 (mianownik)')
pB2 <- pB2 + geom_tile()
pB2 <- pB2 + geom_text(aes(label = round(value, 1)), size=3)
pB2 <- pB2 + scale_fill_gradientn(colours = myPalette(100), name='potega\nliczby 10')
pB2 <- pB2 + scale_x_discrete(expand = c(0, 0))
pB2 <- pB2 + scale_y_discrete(expand = c(0, 0))
pB2 <- pB2 + theme_bw()
pB2 <- pB2 + ggtitle('Czynniki Bayesa (MCMC)')
pB2 <- pB2 + coord_equal()
pB2 <- pB2 + theme(legend.position=c(0.5, -0.25),
                   legend.direction='horizontal',
                   plot.margin = unit(c(0,0,1.5,0), "cm"),
                   plot.title=element_text(hjust=0.5))
plot(pB2)
@
\caption{Czynniki Bayesa policzone za pomocą MCMC} \label{fig:BayesMCMC}
\end{subfigure}
\caption{Czynniki Bayesa} \label{fig:czynnikBayesa}
\end{figure}

\textit{W~bardziej skomplikowanych niż prezentowany w~poniższej pracy modelach często konieczne jest numeryczne obliczenie licznika i~mianownika wzoru na czynnik Bayesa, czyli funkcji wiarygodności brzegowych obu modeli. Można w~tym celu wykorzystać metody klasy MCMC, podobnie jak w~przypadku przybliżania gęstości a~posteriori. Na rysunku \ref{fig:czynnikBayesa}, obok czynnikóœ policzonych analitycznie, przedstawiono czynniki obliczone za pomocą funkcji BayesFactor z~biblioteki MCMCpack.}

Obliczone czynniki Bayesa przedstawiono na rysunku \ref{fig:czynnikBayesa}. Wykresy należy czytać następująco: w~kolumnach znajdują się gęstości zmiennych z~licznika wzoru na czynnik Bayesa, natomiast w~wierszach - z~mianownika. Przykładowo, na wykresie \ref{fig:BayesA} pole na przecięciu wiersza aah oraz kolumny full ma kolor ciemnoczerwony, któremu odpowiada wartości 8. Oznacza to, że czynnik Bayesa, gdzie M1 (licznik) to model \textit{full}, czyli model zawierający wszystkie zmienne, natomiast M2 (mianownik) to model \textit{pte}, czyli zawierający wszystkie zmienne z~wyjątkiem pte, wynosi $10^8$. Kolorami na wykresie zostały oznaczone wartości czynników Bayesa, gdzie wartości kolorów odpowiadają potęgom liczby 10. Taka ilustracja wynika z~interpretacji czynnika Bayesa, która według skali Jeffreysa\footnote{na podstawie wykładu 5: \textit{Elementy wnioskowania w modelach bayesowskich: HPDI, iloraz szans a posteriori, czynnik Bayesa}} zależy od potęgi liczby 10. Przedstawiono ją w~tabeli \ref{tab:jeffreys}.

<<echo=F, results='asis'>>=
sj <- data.frame(BF=c('$<10^0$', '$10^0 - 10^5$', '$10^{0.5}-10^1$', '$10^1-10^{1.5}$', '$10^{1.5}-10^2$', '$>10^2$'),
                 potega=c('$<0$', '$0-0.5$', '$0.5-1$', '$1-1.5$', '$1.5-2$', '$>2$'),
                 interpretacja=c('negative (supports $M_2$)', 'barely worth mentioning', 'substantial', 'strong', 'very strong', 'decisive'))
sjxt <- xtable(sj, caption='Interpretacja wartości czynnika Bayesa według Jeffreysa', label='tab:jeffreys')
print(sjxt, sanitize.text.function=function(x){x})
@

Na podstawie rysunku \ref{fig:czynnikBayesa} oraz tabeli \ref{tab:jeffreys} można wyciągnąć następujące wnioski (spostrzeżenia):

\begin{enumerate}
    \item Każdy z~wykresów przedstawiających czynniki Bayesa jest antysymetryczny (chociaż oś symetrii biegnie po przeciwległej przekątnej niż w~zwykłych macierzach). Jest to ciekawa własność skali Jeffreysa. 
    \item Oba sposoby liczenia czynnika Bayesa wskazały, że model full (ze wszystkimi zmiennymi) jest zdecydowanie lepszy od modelu bez zmiennej aah (średnia liczba przepracowanych godzin) - jest to o~tyle ciekawe, że jedynie ta zmienna miała większą wariancję a~posteriori niż a~priori, a~więc początkowo mogła wydawać się zbędna, wręcz - szkodliwa).
    \item Równie \textit{istotną} zmienną jest pse (wydatki soacjalne państwa), chociaż w~analizie MCMC model z~tą zmienną jest \textit{tylko bardzo silnie} lepszy od modelu bez tej zmiennej, natomiast w~analizie analitycznej jest zdecydowanie lepszy. 
    \item Wątpliwości budzi rozbieżność wyników dotyczących zmiennej pue (wydatki państwa na zasiłki dla bezrobotnych) pomiędzy analizą anlityczną i~MCMC. Szczególnie, że parametr a~posteriori przy tej zmiennej znaczenie zmniejszył swoją wariancję w~porównaniu do a~priori w~obu analizach. 
    \item Obie analizy dały podobne wyniki, chociaż analiza MCMC znacznie ostrożniej szacuje wartości czynnika Bayesa.
\end{enumerate}

\end{document}

