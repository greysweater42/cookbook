---
title: "learning tensorflow"
date: 2019-08-05T18:45:18+02:00
draft: false
categories: ["Python", "Machine learning"]
---



<p>The best way to gain intuiton to any new thing you learn is to start from a very beginning and play with it (<em>let’s see what happens if I do this</em>). That’s the power of reinforcement learning ;)</p>
<p>These packages will be useful in the nearest future:</p>
<pre class="python"><code>import numpy as np
from sklearn.datasets import load_iris
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import accuracy_score
import tensorflow as tf
tf.logging.set_verbosity(tf.logging.ERROR)  # ignore warnings</code></pre>
<p>A trivial example of tensorflow:</p>
<pre class="python"><code>import tensorflow as tf
a = tf.Variable(10, name=&#39;a&#39;)  # a variable
b = tf.Variable(12, name=&#39;b&#39;)  # another variable
s = a + b  # a tensor
sess = tf.Session()
sess.run(a.initializer)
sess.run(b.initializer)
print(sess.run(s))</code></pre>
<pre><code>## 22</code></pre>
<p>As you can see, one does not simply add two numbers in tensorflow.</p>
<ul>
<li>lesson #1: you cannot initialize a tensor</li>
</ul>
<pre class="python"><code>sess = tf.Session()
sess.run(a.initializer)
sess.run(b.initializer)
# print(s.eval())  # does not work - you eval() is not connected to the session
# anyhow
print(sess.run(s))</code></pre>
<pre><code>## 22</code></pre>
<ul>
<li>lesson #2: eval does not recognize session by itself</li>
</ul>
<pre class="python"><code>with tf.Session() as sess:
    sess.run(a.initializer)
    sess.run(b.initializer)
    print(s.eval())  # does work - eval recognizes a default session</code></pre>
<pre><code>## 22</code></pre>
<ul>
<li><p>lesson #2: eval works in <code>with</code> clause</p></li>
<li><p>lesson #3: so far there are 2 ways to initialize a variable in a session</p></li>
</ul>
<pre class="python"><code>init = tf.global_variables_initializer()
with tf.Session() as sess:
    init.run()
    print(s.eval())</code></pre>
<pre><code>## 22</code></pre>
<ul>
<li>lesson #4: the third and most compact way to initialize variables - all the variables in one statement</li>
</ul>
<pre class="python"><code>s1 = tf.add(a, b)  # a tensor, not variable
with tf.Session() as sess:
    init.run()
    print(s1.eval())</code></pre>
<pre><code>## 22</code></pre>
<ul>
<li>lesson #5: tensorflow has it’s own mathematical functions</li>
</ul>
<pre class="python"><code>c = tf.Variable(np.array([[1, 2], [3, 4]]), name=&#39;c&#39;)
d = tf.Variable(np.array([[5, 6], [7, 8]]), name=&#39;d&#39;)
m = tf.matmul(c, d)  # a tensor again
init = tf.global_variables_initializer()
with tf.Session() as sess:
    init.run()
    print(m.eval())</code></pre>
<pre><code>## [[19 22]
##  [43 50]]</code></pre>
<ul>
<li>lesson #6: tensorflow can interpret numpy arrays as matrices</li>
<li>lesson #7: you can multiply matrices!</li>
</ul>
<pre class="python"><code>iris = load_iris()
data = iris.data
y = tf.Variable(data[:, 0].reshape(150, 1), name=&#39;y&#39;)
x0 = np.ones(150).reshape(150, 1)
x0_X = np.concatenate((x0, data[:, 1:]), axis=1)
X = tf.Variable(x0_X, name=&#39;X&#39;)
cov = tf.matmul(tf.transpose(X), X, name=&#39;cov&#39;)
inv_cov = tf.matrix_inverse(cov, name=&#39;inv_cov&#39;)
xy = tf.matmul(tf.transpose(X), y, name=&#39;xy&#39;)
beta = tf.matmul(inv_cov, xy)
init = tf.global_variables_initializer()
with tf.Session() as sess:
    init.run()
    print(beta.eval())</code></pre>
<pre><code>## [[ 1.8450608 ]
##  [ 0.65486424]
##  [ 0.71106291]
##  [-0.56256786]]</code></pre>
<pre class="python"><code>lr = LinearRegression()
lr.fit(data[:, 1:], data[:, 0])
print(np.concatenate((np.array([lr.intercept_]), lr.coef_)))</code></pre>
<pre><code>## [ 1.8450608   0.65486424  0.71106291 -0.56256786]</code></pre>
<ul>
<li>lesson #8: when creating a tensorflow vector, ou have to provide information if it’s horizontal or mathematical, just like in mathematics lesson #9: tensorflow gives the same results as sklearn (linear regression)</li>
</ul>
<p>the code above looks quite like a mess, let’s clear it up</p>
<pre class="python"><code>def get_data(tensorflow=True):
    iris = load_iris()
    data = iris.data
    y = data[:, 0].reshape(150, 1)
    x0 = np.ones(150).reshape(150, 1)
    X = np.concatenate((x0, data[:, 1:]), axis=1)
    if tensorflow:
        y = tf.constant(y, name=&#39;y&#39;)
        X = tf.constant(X, name=&#39;X&#39;)  # constant is a tensor
    return X, y
def construct_beta_graph(X, y):
    cov = tf.matmul(tf.transpose(X), X, name=&#39;cov&#39;)
    inv_cov = tf.matrix_inverse(cov, name=&#39;inv_cov&#39;)
    xy = tf.matmul(tf.transpose(X), y, name=&#39;xy&#39;)
    beta = tf.matmul(inv_cov, xy, name=&#39;beta&#39;)
    return beta
X, y = get_data()
beta = construct_beta_graph(X, y)
mse = tf.reduce_mean(tf.square(y - tf.matmul(X, beta)))
init = tf.global_variables_initializer()
with tf.Session() as sess:
    init.run()
    print(beta.eval())
    print(mse.eval())</code></pre>
<pre><code>## [[ 1.8450608 ]
##  [ 0.65486424]
##  [ 0.71106291]
##  [-0.56256786]]
## 0.09589065804790765</code></pre>
<ul>
<li>lesson #10: you can easily divide your code into modules to make it easier to read lesson #11: when dealing with input data, you can use tf.constant instead of tf.Variable, as the data never changes; constant is a tensor</li>
</ul>
<pre class="python"><code>X, y = get_data()
learning_rate = 0.0001
beta = tf.Variable(np.random.rand(4).reshape(4, 1))
gradient = tf.matmul(tf.transpose(X), tf.matmul(X, beta) - y)
new_beta = beta - learning_rate * gradient
mse_old = tf.reduce_mean(tf.square(y - tf.matmul(X, beta)))
mse_new = tf.reduce_mean(tf.square(y - tf.matmul(X, new_beta)))
init = tf.global_variables_initializer()
with tf.Session() as sess:
    init.run()
    print(beta.eval())
    print(new_beta.eval())
    print(mse_old.eval())
    print(mse_new.eval())</code></pre>
<pre><code>## [[0.92819176]
##  [0.09560371]
##  [0.5765956 ]
##  [0.43947336]]
## [[0.95712909]
##  [0.18666188]
##  [0.66956239]
##  [0.46707814]]
## 4.2490136427077125
## 2.2826438136530784</code></pre>
<ul>
<li>lesson #12: you can calculate the gradient of mse pretty simply on a piece of paper</li>
</ul>
<pre class="python"><code>X, y = get_data()
learning_rate = 0.01
beta = tf.Variable(np.random.rand(4).reshape(4, 1))
gradient = 2 / 150 * tf.matmul(tf.transpose(X), tf.matmul(X, beta) - y)
_training = tf.assign(beta, beta - learning_rate * gradient)
mse = tf.reduce_mean(tf.square(y - tf.matmul(X, beta)))
init = tf.global_variables_initializer()
with tf.Session() as sess:
    init.run()
    for i in range(100):
        _training.eval()
        print(mse.eval())
    print(beta.eval())</code></pre>
<pre><code>## 2.3295754458834392
## 2.1732636866961443
## 2.0346169307319624
## 1.9069202601534183
## 1.7883436567776279
## 1.6780451419465265
## 1.5754089772864712
## 1.479894889153158
## 1.3910065103675586
## 1.308283202262706
## 1.231296573226523
## 1.1596480435109984
## 1.0929667359668156
## 1.0309075438679014
## 0.9731493389342052
## 0.9193933050209722
## 0.8693613878097187
## 0.8227948522591919
## 0.7794529402936862
## 0.7391116217572771
## 0.7015624321524913
## 0.6666113911333307
## 0.6340779961417694
## 0.6037942859667127
## 0.5756039693671849
## 0.5493616142390634
## 0.5249318931187691
## 0.5021888811096067
## 0.48101540258841075
## 0.4613024233032275
## 0.4429484847082431
## 0.42585917760131087
## 0.40994665233330896
## 0.3951291630483135
## 0.38133064359011193
## 0.3684803128748704
## 0.3565123076826343
## 0.3453653409625968
## 0.3349823838794276
## 0.3253103699511249
## 0.3162999197434676
## 0.30790508469278405
## 0.3000831087280003
## 0.2927942064552639
## 0.2860013567543726
## 0.27967011071619197
## 0.27376841292463977
## 0.26826643515606
## 0.2631364216332166
## 0.2583525450310887
## 0.253890772487433
## 0.24972874092297265
## 0.2458456410243821
## 0.24222210928817015
## 0.23884012756539016
## 0.2356829295860159
## 0.23273491397803373
## 0.22998156332999783
## 0.2274093688771429
## 0.22500576042033268
## 0.22275904111426129
## 0.220658326786591
## 0.2186934894732178
## 0.2168551048767226
## 0.2151344034754285
## 0.21352322502941476
## 0.21201397624746882
## 0.21059959139535164
## 0.20927349564101377
## 0.2080295709465971
## 0.206862124330272
## 0.20576585833325214
## 0.20473584353876986
## 0.20376749300044336
## 0.20285653844736784
## 0.20199900814248534
## 0.20119120627936216
## 0.200429693810484
## 0.19971127060760888
## 0.19903295886162248
## 0.19839198763577834
## 0.19778577849218373
## 0.19721193211696084
## 0.19666821587469732
## 0.19615255222761674
## 0.195663007959389
## 0.1951977841476741
## 0.19475520683337613
## 0.19433371833820132
## 0.19393186918547378
## 0.19354831058229688
## 0.1931817874240551
## 0.19283113178496594
## 0.1924952568609107
## 0.1921731513331185
## 0.19186387412346362
## 0.19156654951416652
## 0.1912803626065794
## 0.19100455509549688
## 0.19073842133706856
## [[0.42025504]
##  [1.11499886]
##  [0.39422814]
##  [0.41884096]]</code></pre>
<ul>
<li>lesson #13: tf.assign - assign one value to another, training tensor is only technical, so we could point that the assignment should be made in every iteration</li>
</ul>
<p>let’s clear the code a little bit</p>
<pre class="python"><code>learning_rate = 0.01
n_iter = 1000
X, y = get_data()
beta = tf.Variable(np.random.rand(4).reshape(4, 1))
gradient = 2 / 150 * tf.matmul(tf.transpose(X), tf.matmul(X, beta) - y)
_training = tf.assign(beta, beta - learning_rate * gradient)
mse = tf.reduce_mean(tf.square(y - tf.matmul(X, beta)))
init = tf.global_variables_initializer()
with tf.Session() as sess:
    init.run()
    for i in range(n_iter):
        _training.eval()
        if not i % 100:
            print(mse.eval())
    print(mse.eval())
    print(beta.eval())</code></pre>
<pre><code>## 1.7093679574958616
## 0.20030421113947847
## 0.18382183784492767
## 0.1704727890606104
## 0.1591797079442907
## 0.1496244854781885
## 0.14153864532184707
## 0.13469522581122614
## 0.12890235883394952
## 0.12399784219711606
## 0.1198827623312179
## [[ 1.29381456e+00]
##  [ 8.61440899e-01]
##  [ 5.07849826e-01]
##  [-5.67892539e-04]]</code></pre>
<p>we can make this even better if we use different starting values in each run</p>
<pre class="python"><code>learning_rate = 0.01
n_iter = 10000
X, y = get_data()
start_values = tf.random_uniform([4, 1], -1, 1, dtype=&quot;float64&quot;)
beta = tf.Variable(start_values, name=&#39;beta&#39;)
mse = tf.reduce_mean(tf.square(y - tf.matmul(X, beta)))
# gradient = 2 / 150 * tf.matmul(tf.transpose(X), tf.matmul(X, beta) - y)
gradient = tf.gradients(mse, [beta])[0]
_training = tf.assign(beta, beta - learning_rate * gradient)  # a tensor
init = tf.global_variables_initializer()
with tf.Session() as sess:
    init.run()
    for i in range(n_iter):
        _training.eval()
        if not i % 1000:
            print(mse.eval())
    print(mse.eval())
    print(beta.eval())</code></pre>
<pre><code>## 3.1717068955724943
## 0.13923698481374477
## 0.11781281397310445
## 0.10951259483335614
## 0.10499828417139187
## 0.10211287246669926
## 0.10016709738779174
## 0.09883458435303784
## 0.09791816896731742
## 0.09728719146529707
## 0.09685296890948715
## [[ 1.5438321 ]
##  [ 0.7300292 ]
##  [ 0.75233217]
##  [-0.63452429]]</code></pre>
<ul>
<li>lesson #14: it is better to use tensorflow starting values, as they change in every run</li>
<li>lesson #15: you can calculate gradient manually by yourself, but you can use numerical algorithms implemented in tf.gradients</li>
</ul>
<pre class="python"><code>learning_rate = 0.01
n_iter = 10000
X, y = get_data()
start_values = tf.random_uniform([4, 1], -1, 1, dtype=&quot;float64&quot;)
beta = tf.Variable(start_values, name=&#39;beta&#39;)
mse = tf.reduce_mean(tf.square(y - tf.matmul(X, beta)))
optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)
_training = optimizer.minimize(mse)  # an operation - a new class of objects
init = tf.global_variables_initializer()
with tf.Session() as sess:
    init.run()
    for i in range(n_iter):
        _training.run()  # operations are being run, not evaluated
        if not i % 1000:
            print(mse.eval())
    print(mse.eval())
    print(beta.eval())</code></pre>
<pre><code>## 9.024296441306896
## 0.1631000197507415
## 0.12118669440558215
## 0.1094026946280297
## 0.10446911387903074
## 0.10166388089992151
## 0.09984208082566694
## 0.09860777286582575
## 0.09776138970013415
## 0.09717909657587963
## 0.09677846399210409
## [[ 1.55568123]
##  [ 0.72709262]
##  [ 0.75062761]
##  [-0.63149175]]</code></pre>
<ul>
<li>lesson #16: an optimizer knows, that it can change variables, not constants</li>
<li>lesson #17: operations (like optimizer) are run, not evaluated</li>
</ul>
<p>you should always use get_variable() insetad of Variable (interesting) <a href="https://stackoverflow.com/questions/37098546/difference-between-variable-and-get-variable-in-tensorflow">link to stackoverflow discussion</a></p>
<pre class="python"><code>learning_rate = 0.01
n_iter = 1000
X_train, y_train = get_data(tensorflow=False)
X = tf.placeholder(&quot;float64&quot;, shape=(None, 4))  # placeholder -
y = tf.placeholder(&quot;float64&quot;, shape=(None, 1))
start_values = tf.random_uniform([4, 1], -1, 1, dtype=&quot;float64&quot;)
beta = tf.Variable(start_values, name=&#39;beta&#39;)
mse = tf.reduce_mean(tf.square(y - tf.matmul(X, beta)))
optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)
_training = optimizer.minimize(mse)
batch_indexes = np.arange(150).reshape(5, 30)
init = tf.global_variables_initializer()
with tf.Session() as sess:
    init.run()
    for i in range(n_iter):
        for batch_index in batch_indexes:
            _training.run(feed_dict={X: X_train[batch_index],
                                     y: y_train[batch_index]})
        if not i % 100:
            print(mse.eval(feed_dict={X: X_train, y: y_train}))
    print(mse.eval(feed_dict={X: X_train, y: y_train}), &quot;- final score&quot;)
    print(beta.eval())</code></pre>
<pre><code>## 0.17935462884992343
## 0.14732814325746096
## 0.13458461992795479
## 0.12629699456785487
## 0.12040808755285912
## 0.11595453021268388
## 0.11245214064206353
## 0.109633761182779
## 0.10733581184973848
## 0.10544801649679468
## 0.10390441507568625 - final score
## [[ 0.97105723]
##  [ 0.87616011]
##  [ 0.81265599]
##  [-0.72636774]]</code></pre>
<ul>
<li>lesson #18: in mini-batch processing it is comfortable to use placeholders</li>
</ul>
<pre class="python"><code>learning_rate = 0.01
iris = load_iris()
X_np, y_np = iris.data, iris.target
ohe = OneHotEncoder(sparse=False)
y_all = ohe.fit_transform(y_np.reshape(len(y_np), 1))
x = tf.placeholder(tf.float64, shape=(4, None))
y = tf.placeholder(tf.float64, shape=(3, None))
W = tf.Variable(tf.random_uniform([3, 4], -1, 1, dtype=&quot;float64&quot;))
b = tf.Variable(tf.random_uniform([3, 1], -1, 1, dtype=&quot;float64&quot;))
mult = tf.matmul(W, x) + b  # broadcasting just like in numpy
y_hat = tf.nn.softmax(mult, axis=0)
error = tf.reduce_mean(tf.square(y - y_hat))
optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)
_training = optimizer.minimize(error)
init = tf.global_variables_initializer()
batches = np.arange(150).reshape(5, 30)
with tf.Session() as sess:
    sess.run(init)
    for i in range(1000):
        for batch in batches:
            _training.run(feed_dict={x: X_np[batch].transpose(),
                                     y: y_all[batch].transpose()})
        if not i % 100:
            print(error.eval(feed_dict={x: X_np.transpose(),
                                        y: y_all.transpose()}))
    preds = y_hat \
        .eval(feed_dict={x: X_np.transpose()}) \
        .transpose()</code></pre>
<pre><code>## 0.41299155599157417
## 0.1746964877340377
## 0.12047577656169828
## 0.10342708125082423
## 0.0924723004798974
## 0.08403145782583225
## 0.07712688399194469
## 0.07133813747282311
## 0.06642046223816261
## 0.06220403732309632</code></pre>
<pre class="python"><code>def calculate_accuracy(preds):
    preds_max = np.amax(preds, axis=1)
    max_indexes = []
    for pred, pred_max in zip(preds, preds_max):
        prediction = np.where(pred == pred_max)[0][0]
        max_indexes.append(prediction)
    preds_cat = np.array(max_indexes)
    return(accuracy_score(y_np, preds_cat))
calculate_accuracy(preds)  # maybe overfitting?</code></pre>
<ul>
<li>lesson #19: tf.reshape is NOT the same as tf.transpose</li>
<li>lesson #20: tf.nn.softmax works on rows, not columns. Oh, that’s nice. You can provide “axis” parameter in this function</li>
<li><p>lesson #21: in tensorflow you will find broadcasting, just like in numpy</p></li>
<li><p>name_scope</p></li>
</ul>
<pre class="python"><code>with tf.name_scope(&quot;constants&quot;):
    a = tf.constant(10, name=&#39;a&#39;)
    b = tf.constant(12, name=&#39;b&#39;)</code></pre>
<ul>
<li>and variable scope</li>
</ul>
<pre class="python"><code>with tf.variable_scope(&quot;variables&quot;):
    c = tf.constant(20, name=&#39;c&#39;)
    d = tf.constant(22, name=&#39;d&#39;)</code></pre>
<pre class="python"><code>learning_rate = 0.01
iris = load_iris()
X_np, y_np = iris.data, iris.target
ohe = OneHotEncoder(sparse=False)
y_all = ohe.fit_transform(y_np.reshape(len(y_np), 1))
x = tf.placeholder(tf.float64, shape=(None, 4), name=&#39;x&#39;)
y = tf.placeholder(tf.float64, shape=(None, 3), name=&#39;y&#39;)
W0 = tf.Variable(tf.random_uniform([4, 3], -1, 1, dtype=tf.float64), name=&#39;W0&#39;)
b0 = tf.Variable(tf.random_uniform([1, 3], -1, 1, dtype=tf.float64), name=&#39;b0&#39;)  # will broadcast
h = tf.nn.softmax(tf.matmul(x, W0) + b0)
W1 = tf.Variable(tf.random_uniform([3, 3], -1, 1, dtype=tf.float64), name=&#39;W1&#39;)
b1 = tf.Variable(tf.random_uniform([1, 3], -1, 1, dtype=tf.float64), name=&#39;b1&#39;)
y_hat = tf.nn.softmax(tf.matmul(h, W1) + b1)
error = tf.reduce_mean(tf.square(y - y_hat))
optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)
_training = optimizer.minimize(error)
init = tf.global_variables_initializer()
batches = np.arange(150).reshape(5, 30)
with tf.Session() as sess:
    sess.run(init)
    for i in range(10000):
        for batch in batches:
            _training.run(feed_dict={x: X_np[batch], y: y_all[batch]})
        if not i % 1000:
            print(error.eval(feed_dict={x: X_np, y: y_all}))
    preds = y_hat.eval(feed_dict={x: X_np})</code></pre>
<pre><code>## 0.23685565224356123
## 0.1251924807708239
## 0.11616797720424207
## 0.11154800952411993
## 0.0999466656714496
## 0.08563656572527595
## 0.07438614606309286
## 0.06565962722131301
## 0.05864108551115002
## 0.052877551162326716</code></pre>
<pre class="python"><code>print(calculate_accuracy(preds))  # maybe overfitting?</code></pre>
<pre><code>## 0.9466666666666667</code></pre>
<ul>
<li>lesson #21: deeper neaural networks converge much more slowly</li>
</ul>
<pre class="python"><code>learning_rate = 0.01
iris = load_iris()
X_np, y_np = iris.data, iris.target
ohe = OneHotEncoder(sparse=False)
y_all = ohe.fit_transform(y_np.reshape(len(y_np), 1))
x = tf.placeholder(tf.float64, shape=(None, 4), name=&#39;x&#39;)
y = tf.placeholder(tf.float64, shape=(None, 3), name=&#39;y&#39;)
with tf.variable_scope(&#39;layer1&#39;):
    W0 = tf.Variable(tf.random_uniform([4, 3], -1, 1, dtype=tf.float64))
    b0 = tf.Variable(tf.random_uniform([1, 3], -1, 1, dtype=tf.float64))
    h = tf.nn.softmax(tf.matmul(x, W0) + b0)
with tf.variable_scope(&#39;layer2&#39;):
    W1 = tf.Variable(tf.random_uniform([3, 3], -1, 1, dtype=tf.float64))
    b1 = tf.Variable(tf.random_uniform([1, 3], -1, 1, dtype=tf.float64))
    y_hat = tf.nn.softmax(tf.matmul(h, W1) + b1)
with tf.variable_scope(&#39;training&#39;):
    error = tf.reduce_mean(tf.square(y - y_hat))
    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)
    _training = optimizer.minimize(error)
init = tf.global_variables_initializer()
batches = np.arange(150).reshape(5, 30)
with tf.Session() as sess:
    sess.run(init)
    for i in range(10000):
        for batch in batches:
            _training.run(feed_dict={x: X_np[batch], y: y_all[batch]})
        if not i % 1000:
            print(error.eval(feed_dict={x: X_np, y: y_all}))
    preds = y_hat.eval(feed_dict={x: X_np})</code></pre>
<pre><code>## 0.23053037694323764
## 0.11904168924209908
## 0.09888937671668402
## 0.08328489273210639
## 0.07130697975588017
## 0.06239473230229392
## 0.0556312545018196
## 0.05038024428832492
## 0.04621930568676834
## 0.04285782378008346</code></pre>
<pre class="python"><code>print(calculate_accuracy(preds))  # maybe overfitting?</code></pre>
<pre><code>## 0.9666666666666667</code></pre>
<pre class="python"><code>learning_rate = 0.01
iris = load_iris()
X_np, y_np = iris.data, iris.target
ohe = OneHotEncoder(sparse=False)
y_all = ohe.fit_transform(y_np.reshape(len(y_np), 1))
x = tf.placeholder(tf.float64, shape=(None, 4), name=&#39;x&#39;)
y = tf.placeholder(tf.float64, shape=(None, 3), name=&#39;y&#39;)
def neural_layer(scope_name, x, input_size, output_size, func):
    with tf.variable_scope(scope_name):
        W_shape = [input_size, output_size]
        b_shape = [1, output_size]
        W = tf.Variable(tf.random_uniform(W_shape, -1, 1, dtype=tf.float64))
        b = tf.Variable(tf.random_uniform(b_shape, -1, 1, dtype=tf.float64))
        z = func(tf.matmul(x, W) + b)
    return z
h = neural_layer(&#39;layer1&#39;, x, 4, 3, tf.nn.relu)
y_hat = neural_layer(&#39;layer1&#39;, h, 3, 3, tf.nn.softmax)
with tf.variable_scope(&#39;training&#39;):
    error = tf.reduce_mean(tf.square(y - y_hat))
    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)
    _training = optimizer.minimize(error)
init = tf.global_variables_initializer()
batches = np.arange(150).reshape(5, 30)
with tf.Session() as sess:
    sess.run(init)
    for i in range(10000):
        for batch in batches:
            _training.run(feed_dict={x: X_np[batch], y: y_all[batch]})
        if not i % 1000:
            print(error.eval(feed_dict={x: X_np, y: y_all}))
    preds = y_hat.eval(feed_dict={x: X_np})</code></pre>
<pre><code>## 0.44425343302870346
## 0.10993875085147126
## 0.05731574348176702
## 0.037190762322512456
## 0.02858979024109989
## 0.02403570502181115
## 0.021211114701959227
## 0.019252899362620434
## 0.017790661293384455
## 0.016642559088551813</code></pre>
<pre class="python"><code>print(calculate_accuracy(preds))  # maybe overfitting?</code></pre>
<pre><code>## 0.98</code></pre>
